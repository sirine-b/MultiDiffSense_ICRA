# configs/controlnet_train.yaml
# MultiDiffSense — ControlNet Training Configuration

data:
  # Root directory containing the assembled dataset.
  # Images live in source/ and target/ at this level:
  #
  #   datasets/
  #   ├── source/            ← all depth maps (shared across splits)
  #   ├── target/            ← all tactile images (shared across splits)
  #   ├── prompt.json        ← full prompt file
  #   ├── train/prompt.json  ← train split (prompt entries only, no images)
  #   ├── val/prompt.json    ← val split
  #   └── test/prompt.json   ← test split
  #
  # The prompt paths are relative to dataset_dir, e.g.:
  #   {"source": "source/1_0.png", "target": "target/1_ViTac_0.png", ...}
  dataset_dir: "datasets/"

  # Split-specific prompt files
  train_prompt: "datasets/train/prompt.json"
  val_prompt: "datasets/val/prompt.json"
  test_prompt: "datasets/test/prompt.json"

  # Image resolution (source and target will be resized to this)
  image_size: 512

model:
  # Path to ControlNet initialisation checkpoint
  # Created by running: python tool_add_control.py models/v1-5-pruned.ckpt models/control_sd15_ini.ckpt
  resume_path: "models/control_sd15_ini.ckpt"

  # ControlNet + SD1.5 architecture config
  # Path updated to point to the provided config under `models/`.
  controlnet_config: "models/cldm_v15.yaml"

training:
  batch_size: 8
  learning_rate: 1.0e-5
  max_epochs: 350
  precision: 32

  # Freeze Stable Diffusion UNet backbone (only train ControlNet)
  sd_locked: true
  only_mid_control: false

  # Early stopping
  early_stop_patience: 10
  early_stop_monitor: "val/loss"

  # Logging
  log_every_n_steps: 200
  image_log_frequency: 300  # Log sample images every N batches
  val_check_interval: 1.0   # Validate every epoch

  # DataLoader
  num_workers: 4
  pin_memory: true

  # Output
  output_dir: "results"